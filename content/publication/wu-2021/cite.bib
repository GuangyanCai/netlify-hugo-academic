@article{wu2021,
 abstract = {The continued advancements of time-of-flight imaging devices have enabled new imaging pipelines with numerous applications. Consequently, several forward rendering techniques capable of accurately and efficiently simulating these devices have been introduced. However, general-purpose differentiable rendering techniques that estimate derivatives of time-of-flight images are still lacking. In this paper, we introduce a new theory of differentiable time-gated rendering that enjoys the generality of differentiating with respect to arbitrary scene parameters. Our theory also allows the design of advanced Monte Carlo estimators capable of handling cameras with near-delta or discontinuous time gates.We validate our theory by comparing derivatives generated with our technique and finite differences. Further, we demonstrate the usefulness of our technique using a few proof-of-concept inverse-rendering examples that simulate several time-of-flight imaging scenarios.},
 address = {New York, NY, USA},
 articleno = {287},
 author = {Wu, Lifan and Cai, Guangyan and Ramamoorthi, Ravi and Zhao, Shuang},
 doi = {10.1145/3478513.3480489},
 issn = {0730-0301},
 issue_date = {December 2021},
 journal = {ACM Trans. Graph.},
 month = {dec},
 number = {6},
 numpages = {16},
 publisher = {Association for Computing Machinery},
 title = {Differentiable Time-Gated Rendering},
 url = {https://doi.org/10.1145/3478513.3480489},
 volume = {40},
 year = {2021}
}

